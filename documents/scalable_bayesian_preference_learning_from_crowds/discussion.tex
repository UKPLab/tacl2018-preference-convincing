\section{Conclusions}

We proposed a novel Bayesian preference learning approach 
for modelling both the preferences of individual users 
and the overall consensus of a crowd. 
Our model learns the latent utilities of items from pairwise comparisons 
using a combination of Gaussian processes and Bayesian matrix factorization 
to capture divergences in opinion.
Unlike previous work, our method can scale to arbitrarily large datasets,
since its computational and memory complexity  are bounded independently of dataset size
through the use of stochastic variational inference.
Our empirical results confirm that our approach scales well with the amount of training data,
and that jointly modelling the consensus and personal preferences of users can improve the predictions
of both.
On a benchmark recommendation dataset, our approach performs competitively
with rival methods with inferior computational and memory complexity,
despite the approximations required for our stochastic inference method.
When predicting a consensus from crowdsourced data, our model, CrowdGPPL, improves on 
the previous state of the art~\citep{simpson2018finding},
which did not account for personal preferences.
%far better than previous
%Gaussian process preference learning methods 
%without harming  
%performance on individual utility prediction and significantly improving performance
%on consensus learning.
Future work will evaluate the benefit of learning inducing point locations from data and
optimizing length-scale hyperparameters by maximizing $\mathcal L$.
%and investigate the possibility of integrating deep generative models 
%for learning feature representations from input data.
%the models can readily be adapted to regression or classification tasks by swapping out the preference likelihood, resulting in 
%different values for $\bs G$ and $\bs H$.
% Preference elicitation using information theoretic methods.
