\section{Gradient-based Length-scale Optimization}\label{sec:ls}

In the previous sections, we defined preference learning models that 
incorporate GP priors over the latent functions.
The covariances of these GPs are defined by a kernel function $k$, 
typically of the following form:
\begin{flalign}
k_{\bs \theta}(\bs x, \bs x') = \prod_{f=1}^F k_f\left(\frac{|x_f - x_f'|}{l_f}, \bs\theta_f \right)
\textrm{, where } 
\bs \theta = \{l_1,...,l_F, \bs\theta_1,...,\bs \theta_F \}
\label{eq:kernel}
\end{flalign}
where $F$ is the number of features, 
$l_f$ is a length-scale hyper-parameter,
and $\bs \theta_f$ are additional hyper-parameters for an individual 
feature kernel, $k_f$.
Each $k_f$ is a function of the distance between the $f$th feature values in 
feature vectors $\bs x$ and  and $\bs x'$.
The product over features in $k$ means that data points have 
high covariance only if the kernel functions, $k_f$, for all features are high 
(a soft AND operator). 
It is possible to replace the product with a sum, causing covariance to increase
for every $k_f$ that is similar (a soft OR operator),
or other combinations of the individual feature kernels.
The choice of combination over features is therefore an additional hyper-parameter.
% citations? 

The length-scale, $l_f$, controls the smoothness of the function, $k_f$,
across the feature space
and the contribution of each feature to the model. 
If a feature has a large length-scale,
its values, $\bs x$, have less effect on $k_{\bs\theta}(\bs x, \bs x') $
than if it has a shorter length-scale.
Hence, it is important to set $l_f$ to correctly capture feature relevance.
A computationally frugal option is the median heuristic: 
\begin{flalign}
 l_{f,MH} = \frac{1}{F} \mathrm{median}( \{ |x_{i,f} - x_{j,f}| \forall i=1,..,N, \forall j=1,...,N\} ).
\end{flalign}
Given enough samples of $x_f$, the median heuristic will capture the inherent scale 
of a feature and has been shown to work reasonably well for the task of 
comparing distributions~\citep{gretton2012optimal}. However, it is a simple heursitic
with no guarantees of optimality. 
Alternatively, we can choose $l_f$ by Bayesian model selection using 
the type II maximum likelihood method, 
which chooses the value of $l_f$ that 
maximizes the marginal likelihood, $p(\bs y | \bs \theta)$.
Since the marginal likelihoods for our models are intractable, we maximize
the variational lower bound, $\mathcal{L}$, as an approximation (
defined in Equation \ref{eq:lowerbound} for a single user, and Equation \ref{eq:lowerbound_crowd} for the crowd model). 
Optimizing a kernel length-scale in this manner is known as automatic relevance determination (ARD)~\citep{rasmussen_gaussian_2006}, since the optimal
value of $l_f$ depends on the relevance of $f$.

% Removing irrelevant features could improve performance, 
% since it reduces the dimensionality of the space of the preference function.
%A problem when using text data is that large vocabulary sizes and additional linguistic features 
%lead to a large number of dimensions, $D$. 
%The standard maximum likelihood II optimisation requires 
%$\mathcal{O}(D)$ operations to tune each length-scale.
To optimize the length-scales efficiently, we turn to gradient-based methods
 such as L-BFGS-B~\citep{zhu1997algorithm}, which allow us to optimize
 all length-scales simultaneously, rather than one-by-one.
 For the single user model, the required gradients of $\mathcal{L}(q)$
(Equation \ref{eq:lowerbound}) with respect to $l_f$ are as follows:
%Following the derivations in Appendix \ref{sec:vb_eqns}, Equation \ref{eq:gradient_ls},
\begin{flalign}
\nabla_{l_f}\mathcal{L}(q) & =  
 - \frac{1}{2}\bigg \{
 \mathbb{E}[s] \hat{\bs f}_{m}^T \bs K_{mm}^{-1} \frac{\partial \bs K_{mm}}{\partial l_f} \bs K_{mm}^{-1} \hat{\bs f}_{m} 
 \nonumber \\
& \hspace{2.5cm} + \mathrm{Tr}\left(
\mathbb{E}[s]\bs S^T\bs K_{mm}^{-1} - 1\right)
 \frac{\partial \bs K_{mm}}{\partial l_f} \bs K_{mm}^{-1}
\bigg\}.
\end{flalign}
A number of terms in the lower bound (Equation \ref{eq:lowerbound})
 contain parameters of the 
variational posteriors, i.e. $\bs f$, $\bs S$, $s$, $a$ and $b$.
Through the variational updates, these terms depend indirectly on the length-scale. 
The derivative of these terms with respect to the length-scale is:

If the variational algorithm has converged, the terms $?$ will be zero: the length-scale
is at a maximum. Hence, these terms can be eliminated in this case. This leads to the


 cancel when the updates have converged...
%*** The symbol f should be replaced with \varphi or f? due to clash with function f.

Multi-user model.

Given the kernel function defined in Equation \ref{eq:kernel}, which
contains a product over features,
the partial derivative of the covariance matrix $\bs K_{mm}$ with respect to 
$l_f$ is given by:
\begin{flalign}
\frac{\partial \bs K_{mm}}{\partial l_f} 
& = \frac{\bs K_{mm}}{k_{f}(|\bs x_{mm,f}, \bs x'_{mm,f}) }
\frac{ \bs k_{l_f}(|\bs x_{mm,f}, \bs x'_{mm,f})}{\partial l_f} \nonumber ,\\
\end{flalign}

The choice of kernel function...
In our implementation, we choose the Mat\`ern $\frac{3}{2}$ kernel function for $k$
due to its general properties of smoothness
~\citep{rasmussen_gaussian_2006}... add in citation that shows its good performance.
 
 For the Mat\`ern $\frac{3}{2}$ kernel, the 
 $\frac{\partial \bs K_{l_d}}{\partial l_d}$ is a matrix, where each 
entry, $i,j$,  is defined by:
\begin{flalign}
& \frac{\partial K_{d,ij}}{\partial l_d} = 
\frac{3\bs |\bs x_{i,d} - \bs x_{j,d}|^2}{l_d^3} \exp\left( - \frac{\sqrt{3} \bs |\bs x_{i,d} - \bs x_{j,d}|}{l_d} \right). &
\label{eq:kernel_der}
\end{flalign}
% is defined by Equation \ref{eq:kernel_der}.
% Since we cannot compute $\bs K$ in high dimensions, in practice we substitute $\bs K_{mm}$ for $\bs K$,
% $\bs S$ for $\bs C$, $\hat{\bs f}_{m}$ for $\hat{\bs f}$ and $\bs\mu_{m}$ for $\bs\mu$ so that 

We can define an optimization procedure for the length-scales...
By following the gradients of the length-scale given by 
