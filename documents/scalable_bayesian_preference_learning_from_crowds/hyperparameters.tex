\section{Gradient-based Length-scale Optimization}\label{sec:ls}

In the previous sections, we defined preference learning models that 
incorporate GP priors over the latent functions.
The covariances of these GPs are defined by a kernel function $k$, 
typically of the following form:
\begin{flalign}
k_{\bs \theta}(\bs x, \bs x') = \prod_{d=1}^D k_d\left(\frac{|x_d - x_d'|}{l_d}, \bs\theta_d \right)
\label{eq:kernel}
\end{flalign}
where $D$ is the number of features, 
$l_d$ is a length-scale hyper-parameter,
and $\bs \theta_d$ are additional hyper-parameters for an individual 
feature kernel, $k_d$.
Each $k_d$ is a function of the distance between the $d$th feature values in 
feature vectors $\bs x$ and  and $\bs x'$.
The product over features in $k$ means that data points have 
high covariance only if the kernel functions, $k_d$, for all features are high 
(a soft AND operator). 
It is possible to replace the product with a sum, causing covariance to increase
for every $k_d$ that is similar (a soft OR operator),
or other combinations of the individual feature kernels.
The choice of combination over features is therefore an additional hyper-parameter.
% citations? 

The length-scale, $l_d$, controls the smoothness of the function, $k_d$,
across the feature space
and the contribution of each feature to the model. 
If a feature has a large length-scale,
its values, $\bs x$, have less effect on $k_{\bs\theta}(\bs x, \bs x') $
than if it has a shorter length-scale.
Hence, it is important to set $l_d$ to correctly capture feature relevance.
A computationally frugal option is the median heuristic: 
\begin{flalign}
 l_{d,MH} = D \mathrm{median}( \{ |x_{i,d} - x_{j,d}| \forall i=1,..,N, \forall j=1,...,N\} ).
\end{flalign}
The motivation is that the median will normalize the feature, so that features
are equally weighted regardless of their scaling. By using a median to perform this 
normalization, extreme values remain outliers with relatively large distances. 
Multiplying the median by the number of features, $D$,
prevents  the average covariance $k_{\bs \theta}(\bs x, \bs x')$ between items
from increasing as we add more features using the 
product kernel in Equation \ref{eq:kernel}.
This heuristic has been shown to work reasonably well for the task of 
comparing distributions~\citep{gretton2012optimal}, but is a simple heursitic
with no guarantees of optimality. 

An alternative method for setting $l_d$ is Bayesian model selection using 
the type II maximum likelihood method, 
which chooses the value of $l_d$ that 
maximizes the marginal likelihood, $p(\bs y | \bs \theta)$.
Since the marginal likelihoods for our models are intractable, we maximize
the value of the variational lower bound, $\mathcal{L}$, after convergence of the
inference algorithm 
(defined in Equation \ref{eq:lowerbound} for a single user, 
and Equation \ref{eq:lowerbound_crowd} for the crowd model). 
Optimizing kernel length-scales in this manner is known as automatic relevance determination (ARD)~\citep{rasmussen_gaussian_2006}, since the optimal
value of $l_d$ depends on the relevance of feature $d$.

% Removing irrelevant features could improve performance, 
% since it reduces the dimensionality of the space of the preference function.
%A problem when using text data is that large vocabulary sizes and additional linguistic features 
%lead to a large number of dimensions, $D$. 
%The standard maximum likelihood II optimisation requires 
%$\mathcal{O}(D)$ operations to tune each length-scale.
To perform ARD on feature $d$, 
we only need to be able to evaluate $\mathcal{L}$ 
after variational inference has converged with any given value of $l_d$.
However, if we can also compute derivatives of $\mathcal{L}$ 
with respect to $l_d$, we can use more efficient gradient-based methods, 
such as L-BFGS-B~\citep{zhu1997algorithm}.
These methods perform iterative optimization, 
using gradients to guide changes for all $D$ length-scales simultaneously.
For the single user model, the required gradient 
with respect to the $d$th length-scale, $l_d$, is as follows:
%Following the derivations in Appendix \ref{sec:vb_eqns}, Equation \ref{eq:gradient_ls},
\begin{flalign}
& \nabla_{l_{\! d}} \mathcal{L} =  
\frac{\partial \mathcal{L}}{\partial \hat{\bs f}_m} \frac{\partial \hat{\bs f}_m}{\partial l_d}
+ \frac{\partial \mathcal{L}}{\partial \bs S^{-1}} \frac{\partial \bs S^{-1}}{\partial l_d}
+ \frac{\partial \mathcal{L}}{\partial a} \frac{\partial a}{\partial l_d}
+ \frac{\partial \mathcal{L}}{\partial b} \frac{\partial b}{\partial l_d}
+ \frac{\partial \mathcal{L}}{\partial \bs K}\frac{\partial \bs K}{\partial l_d}. & 
\end{flalign}
We exploit $S^{-1}$
The terms involving the variational paramters $\hat{\bs f}_m$, $\bs S$, $a$ and $b$ arise because 
they depend indirectly on the length-scale through the expectations 
in the variational factors, $\log q(.)$. 
However, when the variational inference algorithm has converged,
$\mathcal{L}$ is at a maximum,
so the partial derivatives of $\mathcal{L}$ with respect to $\hat{\bs f}_m$, $\bs S$, $a$ and $b$
are zero.
Hence, after convergence, $\nabla_{l_{\! d}} \mathcal{L}$ simplifies to:
\begin{flalign}
 &\nabla_{\!l_{\! d}} \mathcal{L} \longrightarrow 
\frac{1}{2} \mathrm{tr}\!\left(\! \left(
\mathbb{E}[s](\hat{\bs f}_{\! m} \hat{\bs f}_{\! m}^T + \bs S^T)\bs K_{\! mm}^{-1} \! -  \bs I \! \right)
 \!\frac{\partial \bs K_{\! mm}}{\partial l_d} \bs K_{\! mm}^{-1} \right) \!. &
\label{eq:gradient_single}
\end{flalign}
For the crowd model, we assume that $C$ latent item components, $\bs V$ have the same kernel function,
which is also shared with $\bs t$. The gradients with respect to the length-scale, $l_{w,d}$,
for the $d$th item feature are therefore given by:
\begin{flalign}
 &\nabla_{l_{ v,d}} \mathcal{L}_{crowd} \longrightarrow
%  \sum_{c=1}^{C} \bigg\{ \mathbb{E}[s_c] 
%  \hat{\bs v}_{ m,c}^T \bs K_{ mm,v}^{-1} 
% \frac{\partial \bs K_{ mm,v}}{\partial l_{w,d}} \bs K_{ mm,v}^{-1} \hat{\bs v}_{ m,c} 
%  + & \nonumber \\
%  & \mathrm{tr}\left( \left(
% \mathbb{E}[s_c]\bs S_{v,c}^T\bs K_{ mm,v}^{-1}  - \frac{1}{2} \bs I  \right)
%  \frac{\partial \bs K_{ mm,v}}{\partial l_{w,d}} \bs K_{ mm,v}^{-1} \right) \bigg\}
%  + & \nonumber \\
%  & \mathbb{E}[\sigma] 
%  \hat{\bs t}_{ m}^T \bs K_{ mm,t}^{-1} 
% \frac{\partial \bs K_{ mm,t}}{\partial l_{w,d}} \bs K_{ mm,t}^{-1} \hat{\bs t}_{ m} 
%  + \mathrm{tr}\left( \left(
% \mathbb{E}[\sigma]\bs S_{t}^T\bs K_{ mm,t}^{-1}  - \frac{1}{2} \bs I  \right)
%  \frac{\partial \bs K_{ mm,t}}{\partial l_{w,d}} \bs K_{ mm,t}^{-1} \right)
%  & \nonumber \\
% & = 
\frac{1}{2} \mathrm{tr}\left( \left( \sum_{c=1}^{C} \mathbb{E}[s_c] \left\{ \hat{\bs v}_{m,c} 
 \hat{\bs v}_{m,c}^T + \bs S_{v,c}^T \right\}
 \bs K_{ mm,v}^{-1}  - C\bs I  \right)
 \frac{\partial \bs K_{ mm,v}}{\partial l_{w,d}} \bs K_{ mm,v}^{-1} \right)
 & \nonumber \\
 & + \frac{1}{2}\mathrm{tr}\left( \left(
\mathbb{E}[\sigma](\hat{\bs t}_{ m}\hat{\bs t}_{ m}^T + \bs S_{t}^T) \bs K_{ mm,t}^{-1}  
- \bs I  \right)
 \frac{\partial \bs K_{ mm,t}}{\partial l_{w,d}} \bs K_{ mm,t}^{-1} \right)
.&
\label{eq:gradient_crowd_items}
\end{flalign}
% If different kernels are used for different components, then the equation above can be modified to
% simply sum over terms relating to the components with a shared kernel function. 
The gradients for the $d$th user feature length-scale, $l_{w,d}$, follows the same form:
\begin{flalign}
 &\nabla_{l_{w,d}} \mathcal{L}_{crowd} \longrightarrow \frac{1}{2} \mathrm{tr}\left( \left( \sum_{c=1}^{C} \left\{ \hat{\bs w}_{m,c} \hat{\bs w}_{m,c}^T +
\bs \Sigma_c^T\right\} \bs K_{mm,w}^{-1} - C\bs I  \right)
 \frac{\partial \bs K_{mm,w}}{\partial l_{w,d}} \bs K_{mm,w}^{-1} \right)
 . &
\label{eq:gradient_crowd_users}
\end{flalign}

% When combining kernel functions for each features using a product,
% as in Equation \ref{eq:kernel}, the partial derivative of the covariance matrix $\bs K_{mm}$ with respect to 
% $l_d$ is given by:
% \begin{flalign}
% \frac{\partial \bs K_{mm}}{\partial l_d} 
% & = \frac{\bs K_{mm}}{\bs K_{d}}
% \frac{ \bs K_{d}(|\bs x_{mm,d}, \bs x'_{mm,d})}{\partial l_d} \nonumber ,\\
% \end{flalign}
The partial derivative of the covariance matrix $\bs K_{mm}$ with respect to 
$l_d$ depends on the choice of kernel function. 
The Mat\`ern $\frac{3}{2}$ function is a widely-applicable, differentiable kernel function 
that has been shown empirically to outperform other well-established kernels 
such as the squared exponential, and makes weaker assumptions of smoothness of 
the latent function~\citep{rasmussen_gaussian_2006}. 
It is defined as:
\begin{flalign}
k_d\left(\frac{|x_d - x_d'|}{l_d} \right) = \left(1 + \frac{\sqrt{3} | x_d - x_d'|}{l_d}\right) 
\exp \left(- \frac{\sqrt {3} | x_d - x_d'|}{l_d}\right).
\end{flalign}
%For the Mat\`ern $\frac{3}{2}$ kernel,  
Assuming that the kernel functions for each feature, $k_d$, are combined using
a product, as in Equation \ref{eq:kernel}, 
the partial derivative $\frac{\partial \bs K_{mm}}{\partial l_d}$ is a matrix, where each 
entry, $i,j$,  is defined by:
\begin{flalign}
& \frac{\partial K_{mm,ij}}{\partial l_d} = 
\prod_{d'=1, d' \neq d}^D k_{d'}\left(\frac{|x_{d'} - x_{d'}'|}{l_{d'}}\right)
\frac{3 (\bs x_{i,d} - \bs x_{j,d})^2}{l_d^3} \exp\left( - \frac{\sqrt{3} \bs |\bs x_{i,d} - \bs x_{j,d}|}{l_d} \right), &
\label{eq:kernel_der}
\end{flalign}
where we assume the use of Equation to combine kernel functions over features using a product

To make use of Equations \ref{eq:gradient_single} to \ref{eq:kernel_der},
we nest the variational algorithm defined in Section \ref{sec:inf} inside
an iterative gradient-based optimization method.
Optimization then begins with an initial guess for all length-scales, $l_d$,
such as the median heuristic.
Given the current values of $l_d$, the optimizer (e.g. L-BFGS-B)
runs the VB algorithm to convergence, 
computes $\nabla_{l_{\! d}} \mathcal{L}$,
then proposes a new candidate value of $l_d$.
The process repeats until the optimizer converges or reaches a maximum number 
of iterations, and returns the value of $l_d$ that maximized $\mathcal{L}$.

% is defined by Equation \ref{eq:kernel_der}.
% Since we cannot compute $\bs K$ in high dimensions, in practice we substitute $\bs K_{mm}$ for $\bs K$,
% $\bs S$ for $\bs C$, $\hat{\bs f}_{m}$ for $\hat{\bs f}$ and $\bs\mu_{m}$ for $\bs\mu$ so that 
