\todo{ add in table of notations (maybe in the appendix)}

\section{Bayesian Preference Learning for Crowds}\label{sec:model}

%%%% Notes

% Title or name of the model: 
% -- cannot decide this until we get most of the paper complete: will emphasis be on crowds? distilling ground truth
% from noisy sources (Bayesian preference learning for fusing unreliable sources)? user preferences/collaborative filtering?
% -- need a new name to differentiate from Houlsby et al. and Khan et al.?
% -- what are the differences in the model? Let's get the model written up.
% -- should also be some buzzword or word to generate interest: 
%    -- 'variational' is on the up, could be used in paper title
%    -- 'stochastic variational' is also on the up
%    -- 'crowdsourcing' on the way down as at 2010 level
%    -- 'gaussian process' on the way up
%    -- 'matrix factorization' kind of on the way up
%    -- 'scalable' on the way up
%    -- 'interactive learning' on the way down
%    -- 'preference learning' flattish, may be on way up slowly
% -- aimed at crowdsourcing problems (uses a common mean function as consensus?)
% -- other parameters for importance of features?
% -- combined preference learning? Preference aggregation? Collaborative crowdsourced preference learning? Bayesian preference learning for crowds? another word for 'multi-user' or 'many users and many items' vs. crowds?

% TO ADD: Why does the variance in f cancel out when predicting the probability of a pairwise label?
% TO ADD: Why does \sigma disappear if we learn the output scale.

% We also estimate the output scale of the GPs, the latent components, and item bias as part of the 
% variational approximation allowing us to estimate these parameters in a Bayesian manner without 
% resorting to maximum likelihood approaches.

% mention how the noise model deals with inconsistencies in preferences

% \begin{enumerate}
% \item What are the benefits of Bayesian methods and Gaussian processes in particular?
% \item The proposal by \citep{chu2005preference} shows how the advantages of a Bayesian
% approach can be exploited for preference learning by modifying the observation model

% Extensions:
% -- how do we replace the GP with a NN?
% -- would this move us from a Bayesian to an ML solution?
% -- maybe save this for future work? Or add a few lines if we can make it fit with the theme of the paper.
% -- another is to replace the fixed number of clusters with a CRP, then the whole thing can be nonparameteric preference learning with crowds.

%\subsection{Modeling Pairwise Preferences}

% Include the case for one user -- preferences may depend on a number of observed features.

%TODO items or instances?
%TODO prefer the use of 'utility' to 'value' since there is some uncertainty (the evaluations by the users can flip at random)

% this should be introduced in section 1. \citep{handleycomparative} -- compares BT with TM models
For a pair of items, $a$ and $b$, 
$a \succ b$ indicates that $a$ is preferred to $b$.  
% %\begin{equation}
% $y(a, b) = \begin{cases}
% 1 & a \succ b \\
% 0 & b \succ a
% \end{cases}$.
% %\end{equation} 
We assume that items have latent \emph{utilities},
$f(\bs x_a)$ and $f(\bs x_b)$, that represent their value to a user,
and that
utility $f(\bs x_a) : \mathbb{R}^D \mapsto \mathbb{R}$ 
is a function of the item's features, where $\bs x_a$ is a vector of length $D$
containing the features of item $a$.
Hence if $f(\bs x_a) > f(\bs x_b)$, then $a \succ b$,
and we observe a pairwise label $y(a, b)=1$,
assuming that pairwise labels never contain errors.

\citet{thurstone1927law} proposed the \emph{random utility model},
which relaxes the assumption that pairwise labels, $y(a, b)$,
are always consistent with the ordering of $f(\bs x_a)$ and $f(\bs x_b)$.
Under the random utility model, the likelihood $p(y(a,b)=1)$ 
increases as $f_a - f_b$ increases, i.e.,
as the utility of item $a$ increases
relative to the utility of item $b$.
However, since $0 < p(y(a,b)=1) < 1$, the model 
allows for uncertainty about the value of $y(a,b)$,
which accommodates labelling errors or
inconsistency in a user's choices at different points in time.
The uncertainty is lower if the values $f_a$ and $f_b$ are further apart, 
which reflects greater consistency in a user's choices
when their preferences are stronger.
 
The random utility model is defined by a likelihood function that
maps the utilities to the labels, $p(y(a,b))$.
Two important models are the Bradley-Terry model ~\citep{bradley1952rank,plackett1975analysis,luce1959possible},
which assumes a logistic likelihood,
and the Thurstone-Mosteller model, also known as \emph{Thurstone case V}~\citep{thurstone1927law,mosteller2006remarks}, which assumes a probit likelihood.
%or the Thurstone-Mosteller model.
%\begin{align}
%p(y(a, b) | f) & = \frac{1}{1 + \exp( f(\bs x_a) - f(\bs x_b) ) }
%\end{align}
In the Thurstone case V model, 
noise in the observations is explained by a Gaussian-distributed noise term, $\delta \sim \mathcal{N}(0, \sigma^2)$:
\begin{align}
 p(y(a, b) | f(\bs x_a) + \delta_{a}, f(\bs x_b) + \delta_{b} )  
 \hspace{0.9cm} & = \begin{cases}
 1 & \text{if }f(\bs x_a) + \delta_{a} \geq f(b) + \delta_{b} \\
 0 & \text{otherwise,}
 \end{cases} &
 \label{eq:thurstone}
\end{align}
Integrating out the unknown values of $\delta_a$ and $\delta_b$ gives:
\begin{align}
& p( y(a, b) | f(\bs x_a), f(\bs x_b) )  \nonumber\\
& = \int\!\!\!\! \int p( y(a, b) | f(\bs x_a) + \delta_{a}, f(\bs x_b) + \delta_{b} ) \mathcal{N}(\delta_{a}; 0, \sigma^2)\mathcal{N}(\delta_{b}; 0, \sigma^2) d\delta_{a} d\delta_{b} \nonumber\\
& = \Phi\left(\frac{f(\bs x_a) - f(\bs x_b)}{\sqrt{2\sigma^2}}\right) = \Phi\left( z \right), 
\label{eq:plphi}
\end{align}
where $z = \frac{f(\bs x_a) - f(\bs x_b)}{\sqrt{2\sigma^2}}$,
and $\Phi$ is the cumulative distribution function of the standard normal distribution. 

In this paper we follow the Thurstone-Mosteller model as it enables 
more convenient Bayesian inference: 
given a posterior distribution over $f$,
we can compute a posterior $p(y(a,b)=1 | \bs y)$ over test labels
by marginalising $f$ analytically, 
where $\bs y$ is a set of pairwise training labels.
Obtaining the posterior over $f$ is itself challenging, however, 
and therefore in Section $\ref{sec:inf}$ we propose 
an approximate inference method to address this problem.


This likelihood is the basis of Gaussian process preference learning (GPPL)~\citep{chu2005preference}. 
Our formulation differs in that instead of learning the variance of $\delta$, we fix it 
to $0.5$ and scale $f$ to vary the uncertainty in the pairwise labels,
which conveniently leads to $z$ having a denominator of 1.
If we have Gaussian distributions over $f(\bs x_a)$ and $f(\bs x_b)$, they can be marginalized in a simple manner %as Gaussian noise
by modifying $z$:
% we haven't mentioned that f is Gaussian yet. 
\begin{align}
\hat{z} = \frac{\hat{f}_a - \hat{f}_b}{\sqrt{1 + \sigma^2_a + \sigma^2_b - 2\sigma^2_{a,b}} } \label{eq:predict_z}
\end{align}
where $\hat{f}_a$ and $\hat{f}_b$ are the expected values of $f(\bs x_a)$ and $f(\bs x_b)$ respectively, 
$\sigma^2_a$ and $\sigma^2_b$ are the corresponding variances,
and $\sigma^2_{a,b}$ is the covariance between $f(\bs x_a)$ and $f(\bs x_b)$.
The next section introduces a model for the utility function, $f$.

\subsection{Single User Preference Learning}
%TODO check use of 'user' versus 'annotator' terminology throughout, especially in the intro. Is it explicit that the term 'user' is abstract and refers to any of these things?

%First consider modeling the preferences of a single user. In this case, we 
We assume a Gaussian process prior over the utility function, 
%is a function of item features and 
$f \sim \mathcal{GP}(0, k_{\theta}/s)$, where $k_{\theta}$ is a kernel function with hyper-parameters $\theta$, 
and $s$ is an inverse scale drawn from a gamma prior, 
$s \sim \mathcal{G}(\alpha_0, \beta_0)$, with shape $\alpha_0$ and scale $\beta_0$.
The value of $s$ determines the variance of $f$ and therefore its magnitude, which affects the level of certainty
in the pairwise label likelihood (Equation \ref{eq:plphi}).
The kernel function takes numerical item features as inputs and determines the covariance between values of $f$ for different items. 
The choice of kernel function and its hyperparameters controls the shape and smoothness of the function 
across the feature space and is often treated as a model selection problem.
Typical choices of kernel function include the \emph{squared exponential} or \emph{Mat\'ern} functions~\citep{rasmussen_gaussian_2006},
which produce higher covariance between items with similar feature values.
These kernel functions make minimal assumptions and are effective in a wide range of tasks. 
% Covariance of different items with same feature: worth mentioning here? We need to multiply the kernel by a small
% amount < 1 to ensure covariance is not 1 and the values can differ.
We use the kernel function $k_{\theta}$ to compute the covariance matrix $K_{\theta}$,
between a set of $N$ observed items with features $\{ \bs x_1, ..., \bs x_N \}$.

Given a set of $P$ pairwise labels, %for a single user, 
$\bs y=\{y_1,...,y_P\}$,
where %the $p$th label, 
$y_p=y(a_p, b_p)$ is the preference label for items $a_p$ and $b_p$, % refers to items $\{ a_p, b_p \}$.
we can write the joint distribution over all variables as follows:
\begin{flalign}
p\left( \bs{y}, \bs f, s | k_{\theta}, \alpha_0, \beta_0 \right) 
=  \prod_{p=1}^P p( y_p | \bs f ) 
\mathcal{N}(\bs f; \bs 0, \bs K_{\theta}/s) \mathcal{G}(s; \alpha_0, \beta_0) %\nonumber \\
%=  \prod_{p=1}^P \Phi\left( z_p \right) 
%\mathcal{N}(\bs f; \bs 0, \bs K_{\theta}/s) \mathcal{G}(s; \alpha_0, \beta_0), &
\label{eq:joint_single}
\end{flalign}
where 
$\bs f = \{f(\bs {x}_1),...,f(\bs {x}_N)\}$
are the utilities of the $N$ items referred to by $\bs y$,
and $p( y_p | \bs f ) = \Phi\left( z_p \right)$ is the pairwise likelihood (Equation \ref{eq:plphi}). 
%, and $\theta$, $\alpha_0$ and $\beta_0$ are hyper-parameters.
We henceforth refer to this single-user model as \emph{GPPL}.

\subsection{Crowd Preference Learning} \label{sec:crowd_model}

% 0. Consider multiple users, each with a set of observed features.
% 1. imagine augmenting the observed features with a number of latent features (this is kind of what Khan et al. do)
% 2. imagine that the latent features relate preference function values between items and users using the smallest number of features
% 3. hence the observed features are not needed given the latent features, but we can create a hierarchical model where the latent features depend on the observed ones if available.

To predict the individual preferences of users in a crowd,
we could assume an independent GPPL model for each user.
However, a joint model of all users' preferences can
exploit the correlations between different users' interests
to improve predictions when preference data is sparse,
and reduce the memory footprint required to store separate models for all users.
Groups of users may share common interests over certain subsets of items,
for example, in a book recommendation task,
some users may share an interest for one particular genre 
but otherwise prefer different categories of books.
Identifying such correlations between users' interests helps to predict 
the preferences of users for whom we have only observed a small number of preferences.
This is the core idea of recommendation techniques such as collaborative filtering~\citep{resnick1997recommender} and matrix factorisation~\citep{koren2009matrix}.
It may also be beneficial to account for the different 
preferences of individuals when predicting the consensus,
particularly when data is only available from a subset of users,
since their individual preferences may otherwise bias the consensus predictions.
We therefore extend GPPL to \emph{crowdGPPL}, a joint model for 
the preferences of individual users in a crowd as well as the underlying consensus.
 
% is there a better word than 'label sources' for the different sources of implicit feedback or other types of labeling?
%In a scenario with multiple users or label sources, 
For crowdGPPL, 
we represent utilities in a matrix, $\bs{F} \in \mathbb{R}^{N \times U}$,
with $N$ rows corresponding to items and $U$ columns corresponding to users. %, and entries are preference values.
We assume that $\bs F$ is the product of two low-dimensional matrices
plus a vector of consensus utilities, $\bs{t}$, of the $N$ items, as follows:
\begin{equation}
\bs{F} = \bs{V}^T \bs{W} + \bs{t},
\end{equation}
where $\bs{W} \in \mathbb{R}^{C \times U}$ is a latent representation
of the users,
$\bs{V} \in \mathbb{R}^{C \times N}$ is a latent representation of the items,
and $C$ is the number of latent \emph{components}, i.e., dimensions
of the latent representations.
The column $\bs v_{.,a}$ of $\bs V$, and the column $\bs w_{.,j}$ of $\bs W$,
 are latent vector representations of item $a$ and user $j$,
 respectively.
%Users with similar values for a certain feature will have similar preferences for 
%the subset of items with corresponding feature values. 
Each latent component corresponds to a utility function 
for certain items shared by a subset of users.
One component could represent, for example, 
in the case of book recommendation, the membership of certain books to a particular
genre and the interests of certain users in that genre.
%Besides latent features, we may also observe a number of item features, $\bs x$,
%and . 
%There are two ways that observed features can be incorporated into the 
%model: (1) as additional dimensions of V or W (each feature cannot be a member of %both); (2) as input features on which V and W depend. The advantage of the latter is that 
%In the single user model, we assumed a single latent utility function, $f$, of the observed item features. 

For crowdGPPL, we assume that each row of $\bs V$, $\bs v_c=\{ 
v_c(\bs{x}_1),...,v_c(\bs{x}_N)\}$,  
contains evaluations of a latent function, 
$v_c\sim \mathcal{GP}(\bs 0, k_{\theta} /s^{(v)}_c)$,
of item features, $\bs x_a$,
where $k$ is a kernel function, $s^{(v)}_c$ is an inverse function scale,
and $\theta$ are kernel hyperparameters.
%Since our goal is to infer a consensus from a crowd as well as to model individual 
%users' preferences, 
We also assume that $\bs t = \{t(\bs {x}_1),...,t(\bs {x}_N)\}$
contains evaluations of a consensus utility function over item features,
$t\sim \mathcal{GP}(\bs 0, k_{\theta} /s^{(t)})$, which is shared across all users.
Similarly, each row $\bs w_c=\{w_c(\bs u_1),...,w_c(\bs u_U)\}$ 
of $\bs W$ contains evaluations of a latent function,
$w_c \sim \mathcal{GP}(\bs 0, k_{\eta} / s^{(w)}_c)$,
of user features, $\bs u_j$, 
with inverse scale $s^{(w)}_c$ 
and kernel hyperparameters $\eta$.
Therefore, the utilities in $\bs F$ are defined by a
preference function, $f$, which is a weighted sum over the latent functions:
\begin{flalign}
  f(\bs x_a, \bs u_j) = \sum_{c=1}^C  v_c(\bs x_a) w_c(\bs u_j) + t(\bs x_a),
\end{flalign}
\todo{
 The only new point is equation (5), but it is not clear why introducing t. I expected the authors should have more discussion on this.
 }
where $\bs u_j$ are the features of user $j$ and $\bs x_a$ are the features of item $a$.
%We provide a Bayesian treatment to matrix factorization by placing Gaussian process priors over the latent functions.
%differently for each user and item. For example, the observed user feature 'age' may correlate with some latent interests of users, but certain users will deviate from their peer group. 
% what happens if two users have identical features (say, the feature representation
% has only simple values, such as age in years)? They have 1-1 covariance, but there 
% is variance in the GP at one location, so both can be drawn separately from the prior.
%It is not necessary to learn a separate scale for $w_c$, since $v_c$ and $w_c$ are multiplied with each other, making a single $s^{(v)}_c$ equivalent to the product of two separate scales. 
%The choice of $C$ can be treated as a hyperparameter, or modeled using a non-parametric prior, such as 
%the Indian Buffet Process, which assumes an infinite number of latent components ~\citep{ding2010nonparametric}.

For simplicity, we assume fixed values of $C$ in this paper. 
The Bayesian approach avoids overfitting by inferring $s^{(v)}_c \approx 0$ with high probability
for any dimensions that are not required to model the data.
%This section described a Bayesian matrix factorization model, 
%which we will subsequently extend to a preference learning model for crowds of users and label sources. 
% joint distribution
% notes about problems with inference.

\todo{Page 7, equation (5): you might want to cite precedence to this form of equation
e.g. K. Mo, E. Zhong, and Q. Yang. Cross-task crowdsourcing. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '13, pages 677-685, New York, NY, USA, 2013. ACM. ISBN 978-1-4503-2174-7. doi: 10.1145/2487575.2487593. URL http://doi.acm.org/10.1145/2487575.2487593.}
We combine the matrix factorization method with the preference likelihood of Equation \ref{eq:plphi}
to obtain a joint preference model for multiple users, \emph{crowdGPPL}:
%represent a consensus between users,
%if present, while allowing individual users' preferences to deviate from this value through $\bs V^T \bs W$. 
%Hence, $\bs t$ can model the underlying ground truth or consensus in crowdsourcing scenarios, or when using
%multiple label sources to learn preferences for one individual.
\begin{flalign}
p\left( \bs{y}, \bs V, \bs W, \bs t, s_1, ..., s^{(v)}_c, s^{(t)} | k_{\theta}, k_{\eta}, \alpha_0, \beta_0 \right) 
= \prod_{p=1}^P \Phi\left( z_p \right) 
\mathcal{N}(\bs t; \bs 0, \bs K_{\theta} /s^{(t)})
 && \nonumber \\ 
\mathcal{G}({s^{(t)}}; \alpha_0, \beta_0)\prod_{c=1}^C \left\{
\mathcal{N}(\bs v_c; \bs 0, \bs K_{\theta} /s^{(v)}_c) 
\mathcal{N}(\bs w_c; \bs 0, \bs L_{\eta}/s^{(w)}_c) \mathcal{G}(s^{(v)}_c; \alpha_0, \beta_0) \right\}, 
\label{eq:joint_crowd}
\end{flalign}
where 
$z_p = \bs v_{.,a_p}^T \bs{w}_{.,u_p} + t_{a_p} - \bs v_{.,b_p}^T \bs{w}_{.,u_p} - t_{b_p}$,
 $s^{(t)}$ is the inverse scale of $t$,
index $p$ refers to a tuple, $\{u_p, a_p, b_p \}$, which identifies the user and a pair of items,
and $L_{\eta}$ is the prior covariance between user feature vectors computed
using the kernel function $k_{\eta}$.
