\section{Bayesian Preference Learning for Crowds}\label{sec:model}

%%%% Notes

% Title or name of the model: 
% -- cannot decide this until we get most of the paper complete: will emphasis be on crowds? distilling ground truth
% from noisy sources (Bayesian preference learning for fusing unreliable sources)? user preferences/collaborative filtering?
% -- need a new name to differentiate from Houlsby et al. and Khan et al.?
% -- what are the differences in the model? Let's get the model written up.
% -- should also be some buzzword or word to generate interest: 
%    -- 'variational' is on the up, could be used in paper title
%    -- 'stochastic variational' is also on the up
%    -- 'crowdsourcing' on the way down as at 2010 level
%    -- 'gaussian process' on the way up
%    -- 'matrix factorization' kind of on the way up
%    -- 'scalable' on the way up
%    -- 'interactive learning' on the way down
%    -- 'preference learning' flattish, may be on way up slowly
% -- aimed at crowdsourcing problems (uses a common mean function as consensus?)
% -- other parameters for importance of features?
% -- combined preference learning? Preference aggregation? Collaborative crowdsourced preference learning? Bayesian preference learning for crowds? another word for 'multi-user' or 'many users and many items' vs. crowds?

% TO ADD: Why does the variance in f cancel out when predicting the probability of a pairwise label?
% TO ADD: Why does \sigma disappear if we learn the output scale.

% We also estimate the output scale of the GPs, the latent components, and item bias as part of the 
% variational approximation allowing us to estimate these parameters in a Bayesian manner without 
% resorting to maximum likelihood approaches.

% mention how the noise model deals with inconsistencies in preferences

% \begin{enumerate}
% \item What are the benefits of Bayesian methods and Gaussian processes in particular?
% \item The proposal by \citep{chu2005preference} shows how the advantages of a Bayesian
% approach can be exploited for preference learning by modifying the observation model

% Extensions:
% -- how do we replace the GP with a NN?
% -- would this move us from a Bayesian to an ML solution?
% -- maybe save this for future work? Or add a few lines if we can make it fit with the theme of the paper.
% -- another is to replace the fixed number of clusters with a CRP, then the whole thing can be nonparameteric preference learning with crowds.

%\subsection{Modeling Pairwise Preferences}

% Include the case for one user -- preferences may depend on a number of observed features.

%TODO items or instances?
%TODO prefer the use of 'utility' to 'value' since there is some uncertainty (the evaluations by the users can flip at random)

% this should be introduced in section 1. \citep{handleycomparative} -- compares BT with TM models
For a pair of items, $a$ and $b$, we write $a \prec b$ to symbolize that $a$ is preferred to $b$.  
A pairwise label has value $y(a \succ b) =1 $ if $a \prec b$ and $0$ otherwise.
% %\begin{equation}
% $y(a \succ b) = \begin{cases}
% 1 & a \prec b \\
% 0 & b \prec a
% \end{cases}$.
% %\end{equation} 
\citet{thurstone1927law} proposed that the likelihood of pairwise label $y(a,b)=1$ 
increases as the difference between the utilities of $a$ and $b$ increases. 
The uncertainty in the likelihood $p(y(a,b)=1)$ accommodates
 labeling errors or noise in implicit annotations, such as click streams, as well as variability in a user's judgments.
Here, we assume the utility to be a function of the items' features,
$f(\bs x_a)$, where $\bs x_a$ is a vector representation of the features of item $a$.
Pairwise labels are typically modeled using either a logistic likelihood %relationship between the utility function, $f$, and the pairwise labels
defined by the Bradley-Terry model~\citep{bradley1952rank,plackett1975analysis,luce1959possible},
or a probit likelihood given by the Thurstone-Mosteller model, also known as \emph{Thurstone case V}~\citep{thurstone1927law,mosteller2006remarks}.
%or the Thurstone-Mosteller model.
%\begin{align}
%p(y(a \succ b) | f) & = \frac{1}{1 + \exp( f(\bs x_a) - f(\bs x_b) ) }
%\end{align}
We use the latter for our model as it enables $f$ to be marginalized analytically to compute a posterior $p(y(a,b)=1 | \bs y)$,
where $\bs y$ is a set of pairwise training labels.
Noise in the observations is explained by a Gaussian-distributed noise term, $\delta \sim \mathcal{N}(0, 0.5)$:
\begin{align}
 p(y(a \succ b) | f(\bs x_a), f(\bs x_b), \delta_{a}, \delta_{b} )  
 \hspace{0.9cm} & = \begin{cases}
 1 & \text{if }f(\bs x_a) + \delta_{a} \geq f(b) + \delta_{b} \\
 0 & \text{otherwise,}
 \end{cases} &
 \label{eq:thurstone}
\end{align}
Integrating out the unknown values of $\delta_a$ and $\delta_b$ gives:
\begin{align}
p( y(a \succ b) | f(\bs x_a), f(\bs x_b),  ) 
= \Phi\left( z \right) = & \int\int p( y(a \succ b) | f(\bs x_a), f(\bs x_b), , \delta_{a}, \delta_{b} ) \nonumber\\
& \mathcal{N}(\delta_{a}; 0, 0.5)\mathcal{N}(\delta_{b}; 0, 0.5) d\delta_{a} d\delta_{b}, 
\label{eq:plphi}
\end{align}
where $z = f(\bs x_a) - f(\bs x_b)$,
and $\Phi$ is the cumulative distribution function of the standard normal distribution. 
This likelihood is the basis of Gaussian process preference learning (GPPL)~\citep{chu2005preference}. 
Our formulation differs in that instead of learning the variance of $\delta$, we fix it 
to $0.5$ and scale $f$ to vary the uncertainty in the pairwise labels.
If we have distributions over $f(\bs x_a)$ and $f(\bs x_b)$, they can be marginalized in a simple manner %as Gaussian noise
by modifying $z$:
% we haven't mentioned that f is Gaussian yet. 
\begin{align}
\hat{z} = \frac{\mu_a - \mu_b}{\sqrt{1 + \sigma_a + \sigma_b - \sigma_{a,b}} } \label{eq:predict_z}
\end{align}
where $\mu_a$ and $\mu_b$ are the expected values of $f(\bs x_a)$ and $f(\bs x_b)$ respectively, 
$\sigma_a$ and $\sigma_b$ are the corresponding variances,
and $\sigma_{a,b}$ is the covariance between $f(\bs x_a)$ and $f(\bs x_b)$.
We now require a model for the utility function $f$, which we introduce in the next section.

\subsection{Single User Preference Learning}
%TODO check use of 'user' versus 'annotator' terminology throughout, especially in the intro. Is it explicit that the term 'user' is abstract and refers to any of these things?

%First consider modeling the preferences of a single user. In this case, we 
We assume that the utility function, $f$, 
%is a function of item features and 
has a Gaussian process prior: 
$f \sim \mathcal{GP}(0, k_{\theta}/s)$, where $k_{\theta}$ is a kernel function with hyper-parameters $\theta$, 
and $s$ is an inverse scale drawn from a gamma prior, 
$s \sim \mathcal{G}(\alpha_0, \beta_0)$, with shape $\alpha_0$ and scale $\beta_0$.
The value of $s$ determines the variance of $f$ and therefore its magnitude, which affects the level of certainty
in the pairwise label likelihood (Equation \ref{eq:plphi}).
The kernel function takes item features as inputs and determines the covariance between values of $f$ for different items. 
The choice of kernel function and its hyperparameters controls the shape and smoothness of the function 
across the feature space and is often treated as a model selection problem.
Typical choices of kernel function include the \emph{squared exponential} or \emph{Mat\'ern} functions~\citep{rasmussen_gaussian_2006},
which produce higher covariance between items with similar feature values.
These kernel functions make minimal assumptions and so are effective in a wide range of tasks. 
% Covariance of different items with same feature: worth mentioning here? We need to multiply the kernel by a small
% amount < 1 to ensure covariance is not 1 and the values can differ.
Given a set of $P$ pairwise labels, %for a single user, 
$\bs y=\{y_1,...,y_P\}$,
where %the $p$th label, 
$y_p=y(a_p \succ b_p)$, % refers to items $\{ a_p, b_p \}$.
we can write the joint distribution over all variables as follows:
\begin{flalign}
p\left( \bs{y}, \bs f, s | k_{\theta}, \alpha_0, \beta_0 \right) 
=  \prod_{p=1}^P p( y_p | \bs f ) 
\mathcal{N}(\bs f; \bs 0, \bs K_{\theta}/s) \mathcal{G}(s; \alpha_0, \beta_0) %\nonumber \\
%=  \prod_{p=1}^P \Phi\left( z_p \right) 
%\mathcal{N}(\bs f; \bs 0, \bs K_{\theta}/s) \mathcal{G}(s; \alpha_0, \beta_0), &
\label{eq:joint_single}
\end{flalign}
where 
$\bs f = \{f(\bs {x}_1),...,f(\bs {x}_N)\}$
are the utilities of the $N$ items referred to by $\bs y$,
and $p( y_p | \bs f ) = \Phi\left( z_p \right)$ is the pairwise likelihood (Equation \ref{eq:plphi}). 
%, and $\theta$, $\alpha_0$ and $\beta_0$ are hyper-parameters.
We henceforth refer to this single-user model as \emph{GPPL}.

\subsection{Crowd Preference Learning} \label{sec:crowd_model}

% 0. Consider multiple users, each with a set of observed features.
% 1. imagine augmenting the observed features with a number of latent features (this is kind of what Khan et al. do)
% 2. imagine that the latent features relate preference function values between items and users using the smallest number of features
% 3. hence the observed features are not needed given the latent features, but we can create a hierarchical model where the latent features depend on the observed ones if available.

When there are multiple users, we wish to exploit similarities between their utility functions 
%of different users or label sources 
to improve our predictions for each user when faced with sparse data.
% is there a better word than 'label sources' for the different sources of implicit feedback or other types of labeling?
%In a scenario with multiple users or label sources, 
We represent utilities in a matrix, $\bs{F}$,
where $N$ rows correspond to items and $U$ columns correspond to users. %, and entries are preference values.
If we factorize this matrix, we obtain two low-dimensional matrices,
one for users, $\bs{W} \in \mathcal{R}^{C \times U}$, 
and one for the items, $\bs{V} \in \mathcal{R}^{N \times C}$,
where $C$ is the number of latent components:
%$U$ is the number of users, and $N$ is the number of items
$\bs{F} = \bs{V}^T \bs{W}$.
The rows $V_a$ and $W_j$ are latent vector representations of items and users, respectively.
%Users with similar values for a certain feature will have similar preferences for 
%the subset of items with corresponding feature values. 
Latent components correspond to utility functions for certain items shared by multiple users.
These could represent, for example, 
in the case of book recommendation, interests in a particular genre of book. 
%Besides latent features, we may also observe a number of item features, $\bs x$,
%and . 
%There are two ways that observed features can be incorporated into the 
%model: (1) as additional dimensions of V or W (each feature cannot be a member of %both); (2) as input features on which V and W depend. The advantage of the latter is that 
%In the single user model, we assumed a single latent utility function, $f$, of the observed item features. 
For the multi-user case, we assume that there are $C$ latent functions of item features, $v_c$, 
 and $C$ latent functions of user features, $w_c$.
%and thereby model the relationship between each observed feature and each of the latent features. 
The matrices $V$ and $W$ are evaluations of these functions at the points corresponding to 
the users and items observed during training.
Therefore, the latent preference function, $f$, is 
a weighted sum over latent functions:
\begin{flalign}
  f(\bs x_a, \bs u_j) = \sum_{c=1}^C w_c(\bs u_j) v_c(\bs x_a), & & v_c \sim \mathcal{GP}(\bs 0, k_{\theta} /s_c), & & w_c \sim \mathcal{GP}(\bs 0, k_{\theta}),
\end{flalign}
where $\bs u_j$ are the features of user $j$,
and we provide a Bayesian treatment to matrix factorization by placing Gaussian process priors over the latent functions.
%differently for each user and item. For example, the observed user feature 'age' may correlate with some latent interests of users, but certain users will deviate from their peer group. 
% what happens if two users have identical features (say, the feature representation
% has only simple values, such as age in years)? They have 1-1 covariance, but there 
% is variance in the GP at one location, so both can be drawn separately from the prior.
It is not necessary to learn a separate scale for $w_c$, since $v_c$ and $w_c$ are multiplied with each other, making a single $s_c$ equivalent to the product of two separate scales. 
The choice of $C$ can be treated as a hyperparameter, or modeled using a non-parametric prior, such as 
the Indian Buffet Process, which assumes an infinite number of latent components ~\citep{ding2010nonparametric}.
For simplicity, we assume fixed values of $C$ in this paper, and allow 
the Bayesian approach to avoid overfitting by inferring $s_c \approx 0$ with high probability
for any dimensions that are not required to model the data.
%This section described a Bayesian matrix factorization model, 
%which we will subsequently extend to a preference learning model for crowds of users and label sources. 

% joint distribution
% notes about problems with inference.

We combine the matrix factorization method with the preference likelihood of Equation \ref{eq:plphi}
to obtain a joint preference model for multiple users or label sources.
Since our goal is to infer a consensus from a crowd as well as to model individual users' preferences, 
we also introduce a consensus utility function over item features, 
$t\sim \mathcal{GP}(\bs 0, k_{\theta} /\sigma_t)$, that is shared across all users,
with values $\bs t = \{t(\bs {x}_1),...,t(\bs {x}_N)\}$ for the training items.
%represent a consensus between users,
%if present, while allowing individual users' preferences to deviate from this value through $\bs V^T \bs W$. 
%Hence, $\bs t$ can model the underlying ground truth or consensus in crowdsourcing scenarios, or when using
%multiple label sources to learn preferences for one individual.
The joint distribution of our crowd model, \emph{crowdGPPL}, is:
\begin{flalign}
p\left( \bs{y}, \bs V, \bs W, \bs t, s_1, ..., s_C, \sigma_t | k_{\theta}, \alpha_0, \beta_0 \right) 
= \prod_{p=1}^P \Phi\left( z_p \right) 
\mathcal{N}(\bs t; \bs 0, \bs K_{t,\theta} /\sigma_t)
 && \nonumber \\ 
\mathcal{G}({\sigma_t}; \alpha_0, \beta_0)\prod_{c=1}^C \left\{
\mathcal{N}(\bs v_c; \bs 0, \bs K_{v,\theta} /s_c) 
\mathcal{N}(\bs w_c; \bs 0, \bs K_{w,\theta}) \mathcal{G}(s_c; \alpha_0, \beta_0) \right\}, 
\label{eq:joint_crowd}
\end{flalign}
where 
$z_p = \bs v_{.,a_p}^T \bs{w}_{.,u_p} + t_{a_p} - \bs v_{.,b_p}^T \bs{w}_{.,u_p} - t_{b_p}$,
 $\sigma_t$ is the inverse scale of $t$,
and index $p$ refers to a tuple, $\{u_p, a_p, b_p \}$, which identifies the user and a pair of items.
