% Note that Khan's method does not need factorization assumptions in the approximate posterior.
% Instead, they have no prior over v (item features).
% They have a diagonal covariance for the user features -- cheap. 
% They need a separate GP per user but it seems like this is not a problem in practice -- I guess
% the method scales linearly with no. users. In our case, we model covariance between users, so
% scaling is poor unless you can use inducing points or diagonal covariance.


\section{Related Work}
\label{sec:rw}

\subsection{Pairwise Preference Learning} 

To obtain a ranking from pairwise labels, 
many preference learning methods model
the user's choices as a random function of the latent 
\emph{utility} of the items.
Inferring the utilities of items allows us to rank them, estimate numerical ratings
and predict pairwise labels.
Many popular instances of this approach, known as a \emph{random utility model}~\citep{thurstone1927law},
are variants of  
the Bradley-Terry (BT) model~\citep{bradley1952rank,plackett1975analysis,luce1959possible},
or the Thurstone-Mosteller model, also known as \emph{Thurstone case V}~\citep{thurstone1927law,mosteller2006remarks}.
Examples include best-worst scaling~\citet{marley2005some}, which extends the BT model,
and TrueSkill~\citep{herbrich2007trueskill}, a Thurstone case V model that learns 
the skill of game players by treating match outcomes as noisy pairwise labels.
Recent work on the BT model has analysed bounds on error rates~\citep{chen2015spectral}, 
sample complexity~\citep{shah2015estimation}
and developed computationally efficient active learning~\citet{li2018hybrid}.
However, these examples do not consider input features.
Another commonly-used ranking method, SVM-rank~\citep{joachims2002optimizing},
predicts pairwise labels from input features, but optimises
pairwise label prediction directly without a random utility model.
\emph{Gaussian process preference learning (GPPL)}
provides a Bayesian treatment of the random utility model,
using input features to predict the utilities of test items and share information
between similar items~\citep{chu2005preference}.
Here, we build on GPPL to provide a scalable approach that can 
model the preferences of crowds of users.

\subsection{Annotator Disagreements when Estimating a Consensus}

Much of the previous work on preference learning from crowdsourced data 
treats disagreements as annotation errors and infers only the consensus,
rather than modelling personal preferences.
For instance, 
\citet{chen2013pairwise} and \citet{wang2016blind} 
tackle annotator disagreement %between annotators in a crowd 
using Bayesian approaches that learn the labelling accuracy of each worker.
Recently, \citet{pan2018stagewise} and \citet{han2018robust} 
introduced scalable methods that extend this idea from pairwise labels
to noisy \textit{k}-ary preferences,
i.e., totally-ordered subsets of $k$ items.
\citet{fu2016robust} improved SVM-rank by identifying outliers in crowdsourced data
that correspond to probable errors,
while \citet{uchida2017entity} extend SVM-rank to account for different levels of confidence in each pairwise annotation expressed by the annotators.
%TODO decide if this should be added.
%For crowdsourced classification tasks, \citet{simpson2017bayesian} show that modelling 
%individual annotator noise levels in combination with a Gaussian process can improve performance, but this has not yet been adapted for preference learning.
However, while these approaches differentiate the level of \emph{noise}
for each annotator,
personal preferences also introduce labelling \emph{bias}, 
as the differences between users are not random but depend on the items considered.
With small numbers of labels, these biases may reduce the accuracy of the estimated
consensus.
Furthermore, previous aggregation methods for crowdsourced preferences
do not consider the item features,
so cannot predict the utility of test items with no or very few labels~\citep{chen2013pairwise,wang2016blind,han2018robust,pan2018stagewise,li2018hybrid}.
Our approach goes beyond these methods
by predicting personal preferences
and incorporating item features into the model.

\subsection{Inferring Personal Preferences for Members of a Crowd}

A number of methods use matrix factorisation to predict personal preferences 
for members of a crowd from pairwise labels,
including 
\citet{yi_inferring_2013}, who focus on small numbers of pairs per user,
and \citet{salimans2012collaborative}, who apply Bayesian matrix factorisation to 
better handle sparse data.
In matrix factorisation, each individual's preferences are represented 
by a mixture of latent functions.
\citet{kim2014latent} do not apply matrix factorisation, but instead
assume that pairwise labels depend on one of several latent rankings.
However, these techniques do not account for any input features for prediction.

%crowdranking \citet{yi_inferring_2013} uses the crowd to make up for the fact that a target user has small data -- it's a form of collaborative filtering with pairwise labels using a non-Bayesian inference algorithm.
% Several other works learn multiple rankings from crowdsourced pairwise labels
% rather than a single gold-standard ranking, 
% but do not consider the item or user features so cannot extrapolate to new users or 
% items~\citep{yi_inferring_2013,kim2014latent}. 
% Both \citet{yi_inferring_2013} and learn a small number of
% latent ranking functions that can be combined to construct personalized preferences, 
% although neither provide a Bayesian treatment to handle data sparsity.
%include the work on collaborative GPPL
%Several extensions of BMF use Gaussian process priors over latent factors 
%to model correlations between 
%items given side information or observed item features~\citep{adams2010incorporating,zhou2012kernelized,houlsby2012collaborative,bolgar2016bayesian}. 
%However, these techniques are not directly applicable to 
%learning from pairwise comparisons 
%as they assume that the observations are Gaussian-distributed numerical ratings~\citep{shi2017survey}. 

A number of other methods use Gaussian processes 
for personal preference prediction, 
such as by \citet{guo2010gaussian}, who propose a joint Gaussian process over the
space of users and features. Since this scales cubically
in the number of users, \citet{abbasnejad2013learning} 
propose to cluster the users into behavioural groups.
However, distinct clusters do not
allow for collaborative learning between users with partially overlapping preferences, e.g. two users may both like one genre of music, 
while having different preferences over other genres. 
\citet{khan2014scalable} instead learn a GP for each user,
then add a matrix factorization term that performs collaborative filtering.
However, this approach does not model the relationship between
 input features and the latent factors,
 unlike \citet{lawrence2009non} who place GP priors over latent item components.
 Neither of these last two methods
 give a fully Bayesian treatment to the model, as the the users' latent features
 are optimised rather than marginalised.
An alternative is \emph{Collaborative GP (collabGP)}~\citep{houlsby2012collaborative},
which uses a latent factor model, where each latent factor has a Gaussian process prior. 
This allows the model to take advantage of the input features of both
users and items when learning the latent factors. 
However, unlike the approach we propose here, 
none of the methods to date jointly model both consensus 
and personal preferences in a fully-Bayesian manner,
which is needed to handle small amounts of data for both users and items
and account for personal biases when inferring the consensus.
Furthermore, the existing GP-based approaches
suffer from scalability issues due to limitations of their inference methods.

 % PCA: Gaussian noise. "The classical PCA converts a set of samples with possibly correlated variables into another   
 % set of samples with linearly uncorrelated variables via an orthogonal transformation [1]. Based on this, PCA
 % is an effective technique widely used in performing dimensionality reduction and extracting features." -- Shi et al 2017. shi2017survey
 % SVD: like PCA with the mean vector set to zeroes.
 % variations of PCA: for handling outliers or large sparse errors
 % most matrix factorizations are special cases of PCA and in practice do not consider the mean vector.
 % probabilistic PCA: latent variables are unit isotropic Gaussians --> all have 0 covariance and 1 variance.
 % Bayesian PCA: places priors on all latent variables.
 % Probabilistic factor analysis: assumes different variances on each of the latent factors.
 % Probabilistic matrix factorisation: ignores the mean. --> I.e. can be done with SVD
 % I think this means our method is a form of PFA? But extended to consider correlations in the weights.
 % NMF: as matrix factorisation but the low-rank matrices are non-negative.


\subsection{Scalable Approximate Bayesian Inference}

%Scalability of BMF
Many of the approaches for modelling individual user preferences use matrix factorization 
to share information between users and items,
which benefits from a Bayesian treatment to reduce the effects of overfitting or noisy data~\citep{saha2015scalable}.
Recent work on scalable Bayesian matrix factorization focuses on distributing and 
parallelising inference but %these approaches do not make use of input features and 
are not directly applicable when Gaussian processes are used to integrate input features
 ~\citep{ahn2015large,saha2015scalable,vander2017distributed,chen2018large}. 
%This paper focuses instead on reducing computational and memory costs, 
%although the method we propose is amenable to parallelization.

%Scalability of GPs
Models that combine Gaussian processes with non-Gaussian likelihoods 
require approximate inference methods that often scale poorly with 
the amount of training data available. 
Established methods such as the Laplace approximation 
and expectation propagation~\citep{rasmussen_gaussian_2006} have
computational complexity $\mathcal{O}(N^3)$ with $N$ data points
 and memory complexity $\mathcal{O}(N^2)$. 
For collaborative GPPL, \citet{houlsby2012collaborative}
propose a  kernel for pairwise 
preference learning and use a sparse
\emph{generalized fully independent training conditional} (GFITC) 
approximation~\citep{snelson2006sparse} to reduce the computational complexity to $\mathcal{O}(PM^2 + UM^2)$ and 
memory complexity to $\mathcal{O}(PM + UM)$,
where $P$ is the number of pairwise labels, 
$M \ll P$ is a fixed number of inducing points, 
and $U$ is the number of users.
However, this is not sufficiently scalable
for very large numbers of users or pairs, 
due to increasing memory consumption 
and optimisation steps that cannot be run in parallel on subsets of the data, 
since the objective function is a not a sum over data points.
%The marginal likelihood does not factor between data points -- updating for one data point may not 
% improve the marginal likelihood. If the objective function is a sum of terms, we can do gradient 
% descent steps on each term independently.  
%Updates  to the individual factors are not gradient descent steps for the overall objective 
%-- local objective only.
% This means they have some sequential dependencies on one another, so I don't know what
% happens if you do them out of order.
The GP over pairs also means that it does not output posteriors for 
the utilities of individual items, which are useful for ranking,
and can only be trained using pairwise labels, even if observations of the utilities
are available.

To handle large numbers of pairwise labels, \citet{khan2014scalable}
develop a variational EM algorithm and sub-sample pairwise data rather than learning from the complete training set.
An alternative is \emph{stochastic variational inference (SVI)}~\citep{hoffman2013stochastic}, 
which updates an approximation to the posterior using 
a different random sample of the training data at each iteration. 
This allows the approximation to make use of all training data over a number of 
iterations, while limiting training costs per iteration.
SVI has been successfully applied to Gaussian process regression~\citep{hensman2013gaussian} and classification~\citep{hensman2015scalable},
further improving scalability over existing sparse approximations.
For multi-output GPs, ~\citet{nguyen2014collaborative} introduce an SVI approach where 
each output is a weighted combination of shared latent functions plus a latent function specific to that output. 
They apply their method to capture dependencies between regression tasks,
treating the weights for the shared latent functions as hyperparameters. 
In this paper, we also use shared latent functions to capture dependencies between different users' preferences,
but introduce a Bayesian treatment of the weights using a GP over latent user features,
and integrate a non-Gaussian likelihood into the SVI framework to enable learning from pairwise labels.
An SVI method for preference learning that places a GP over items, rather than pairs, 
was previously applied by ~\citet{simpson2018finding}.
However, this method, a variant of GPPL,
did not consider the different preferences of individual users.
Here, we propose a new SVI method, crowdGPPL, aimed at a different task: 
jointly modelling personal preferences of users and the crowd consensus
using a combination of Gaussian processes and Bayesian matrix factorisation.
In Section \ref{sec:inf},
we provide the full details of the SVI method for 
both GPPL, as these were not previously published, then extend the scheme to crowdGPPL.
