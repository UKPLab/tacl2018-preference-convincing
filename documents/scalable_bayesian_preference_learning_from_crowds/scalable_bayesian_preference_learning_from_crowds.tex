
\RequirePackage[fleqn]{amsmath}
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
\documentclass[smallcondensed,natbib]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended,natbib]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}

%\usepackage{times}
%\usepackage{latexsym}
%\usepackage{multirow}
\usepackage{url}
\makeatletter
\makeatother
%\usepackage[hidelinks]{hyperref}
%\DeclareMathOperator*{\argmax}{arg\,max}

% \usepackage{times}
% \usepackage{url}
% \usepackage{latexsym}
% 
\usepackage[fleqn]{amsmath}
% \usepackage{amssymb}
% \usepackage{amstext}
% \usepackage{amsthm}
% 
%\usepackage{cite}

\usepackage{amsfonts}
\usepackage{algorithm2e}
\usepackage{array}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{url}
\usepackage{tabularx}
\usepackage{numprint}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{todonotes}

\newcommand{\bs}{\boldsymbol}  
\newcommand{\wrtd}{\mathrm{d}}

\makeatletter
\makeatother %some sort of hack related to the symbol @

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ 
Scalable Bayesian Preference Learning with Crowds
}

\author{Edwin Simpson 
\and Iryna Gurevych \\
Ubiquitous Knowledge Processing Lab, Dept. of Computer Science, Technische Universit\"at Darmstadt, Germany\\
              \email{\{simpson,gurevych\}@ukp.informatik.tu-darmstadt.de}
}
\date{Received: date}
\begin{document}

\titlerunning{Scalable Bayesian Preference Learning}
\authorrunning{Simpson, E and Gurevych, I}

% do not exceed 20 pages including references

\maketitle

\begin{abstract}
We propose a scalable Bayesian preference learning method 
for jointly inferring a consensus from crowdsourced pairwise labels 
and predicting the preferences of individual annotators.
%While pairwise comparisons are an effective form of training data for ranking or comparison tasks,
Annotators in a crowd may have divergent opinions, making it difficult to identify consensus rankings or ratings from
pairwise labels. Limited, noisy data for each user also presents a challenge when predicting the preferences of individuals. 
%In applications such as recommendation it is also necessary to predict the preferences of individual annotators or users. 
%and identify common preferences between users. % use of the latent factors 
%We address these challenges by combining matrix factorization to model individual preferences with 
%Gaussian processes to integrate user and item features. By taking a Bayesian approach, our model
We address these challenges by combining matrix factorization with 
Gaussian processes in a Bayesian approach that
accounts for uncertainty arising from sparse data and annotation noise.
Previous methods for Gaussian process preference learning (GPPL) do not scale to datasets with large numbers
 of users, items or pairwise labels, so we propose an inference method using stochastic variational inference (SVI)
%that can scale to large numbers of items, users, and pairwise labels 
that can handle constraints on memory and computational costs.
Our experiments on a computational argumentation task
demonstrate the method's scalability and
 show that modeling the preferences of individual annotators in a crowd improves the quality of
the inferred consensus.
On a benchmark recommendation task, our method is competitive with previous approaches, 
 while the model is able to scale to far larger datasets.
%We also show how to  %that robustness to %able to learn the effective number of components required to model the data and
%choosing more latent components than required,
%apply gradient-based optimization to length-scale hyper-parameters to improve performance.
We make our software and documentation publicly available for use in future 
work\footnote{\url{https://github.com/UKPLab/tacl2018-preference-convincing/tree/crowdGPPL}}.
%We show how to make collaborative preference learning work at scale and how it can be used to learn
%a target preference function from crowdsourced data or other noisy preference labels. 
%The collaborative model captures the reliability of each worker or data source and models their biases and error rates. 
%It uses latent factors to share information between similar workers and a target preference function.
%We devise an SVI inference schema to enable the model to scale to real-world datasets.
%Experiments compare results using standard variational inference, laplace approximation and SVI.
%On real-world data we show the benefit of the personalised model over a GP preference learning approach 
%that treats all labels as coming from the same source,
%as well as established alternative methods and classifier baselines.
%We show that the model is able to identify a number of latent features for the workers and for textual arguments.
\end{abstract}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
%\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{intro}
\input{related_work}
\input{model}
\input{inference}
%\input{hyperparameters}
\input{experiments}
\input{discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use section* for acknowledgment
\section*{Acknowledgments}

\bibliographystyle{spbasic}
\bibliography{simpson_scalable_bayesian_pref_learning_from_crowds}

\appendix
\input{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
